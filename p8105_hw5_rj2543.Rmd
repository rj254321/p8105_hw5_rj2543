---
title: "p8105_hw5_rj2543"
author: "rj2543"
date: "November 3, 2018"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(purrr)
```

# Problem 1

The original zip file contains data from a longitudinal study that included a control arm and an experimental arm. Data for each participant is included in a separate file, and file names include the subject ID and arm.

Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time:

* Start with a dataframe containing all file names; the list.files function will help

```{r all file names}
file = list.files(path = "./data") %>% # specify all file names, it may be more useful to use argument "full.names = TRUE" in order to do the following data import
  tibble()
  
file = rename(file, names = .) # make variable name meaningful

file
```

* Iterate over file names and read in data for each subject using purrr::map and saving the result as a new variable in the dataframe

```{r data read in}
file_read = function(x){ # write a function for read in data in the preferred way
    path = str_c("./data/", x) # define the relative path
    
    y = read_csv(path) %>% 
      mutate(patient = x) %>% 
      separate(patient, into = c("id", "remove"), sep = ".c") %>%  
      select(-remove) %>% # use subject ID instead of file name to specify
      select(id, everything()) # make sure subject IDs show first
    y
}

patient = file %>% 
  mutate(info = map(file$names, file_read)) %>% # using purrr::map to read in data for each subjects
  separate(names, into = c("patient_id", "remove1"), sep = ".c") %>% 
  select(patient_id, info) # use subject ID instead of file name to specify individual

patient # data in each file is saved as a new variable called "info"

patient$info[1] # visit specific "info" tibble
```


* Tidy the result; manipulate file names to include control arm and subject ID, make sure weekly observations are “tidy”, and do any other tidying that’s necessary

```{r data tidy}
patient_tidy = patient %>%
  janitor::clean_names() %>% 
  separate(patient_id, into = c("arm", "id"), sep = "_") %>% # specify information about control arm and subjuect ID
  select(id, everything()) %>% 
  mutate(id = as.integer(id)) %>% 
  arrange(id) %>% # arrange data in a reader-friendly way
  unnest() %>% # make weekly observations viable
  select(-id1) # remove repeated subject ID to make weekly observations tidy

patient_tidy
```


Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

```{r spaghetti plot}
plot_patient = function(a){ # write a plot function which can be applied to each subject
  patient_tidy %>%
    gather(key = week, value = obs, week_1:week_8) %>% # prepare data for "aes"
    separate(week, into = c("remove", "week"), sep = "_") %>% 
    select(-remove) %>% 
    filter(id == a) %>% # specify certain subject
    ggplot(aes(x = week, y = obs, group = arm, color = arm)) + # show observations over time with con&exp arms on the same plot for visual comparisons
    geom_point() +
    geom_path() +
    labs(
      title = "Observations over time among control and experimental arms",
      x = "Week",
      y = "Observations",
      caption = str_c("Patient ", a) # specify certain subject
    )
}

map(patient_tidy %>% distinct(id) %>% pull(), plot_patient) # apply plot function to all distinct subjects
```

**For most subjects, experimental arms obtained higher observations than control arms. Also, experimental arms experienced a gradually increasing trend in observations over time while observations of control arms fluctuated. In plots for patient 1, 5, 6, 7 and 8, two observation lines have no intersections. However, for patient 2, 3, 4, 9 and 10, observations of control arms might exceed experimental arms in beginning and middle of the study.**


# Problem 2

The Washington Post has gathered data on homicides in 50 large U.S. cities and made the data available through a GitHub repository. You can read their accompanying article.

```{r data import}
homicide = read_csv("./data2/homicide-data.csv") %>% 
  janitor::clean_names()

homicide
```

* Describe the raw data. 

**Raw data has `r nrow(homicide)` rows for different observations. And `r ncol(homicide)` columns referred to `r names(homicide)` variables.**

* Create a city_state variable (e.g. “Baltimore, MD”) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).

```{r number of homicides}
nhomicide = homicide %>% 
  unite(city, state, col = "city_state", sep = ", ") %>% # create a "city_state" variable
  group_by(city_state) %>% # in order to summarise within cities
  count(disposition == "Closed without arrest") %>% # to specify homicides
  janitor::clean_names() %>% 
  filter(disposition_closed_without_arrest == TRUE) %>% # obtain total number of homicides
  select(-disposition_closed_without_arrest) %>% 
  rename(n_homicide = n)

nunsolved = homicide %>% 
  unite(city, state, col = "city_state", sep = ", ") %>% # create a "city_state" variable
  group_by(city_state) %>% # in order to summarise within cities
  count(disposition == "Open/No arrest") %>% # to specify unsolved homicides
  janitor::clean_names() %>% 
  filter(disposition_open_no_arrest == TRUE) %>% # obtain number of unsolved homicides
  select(-disposition_open_no_arrest) %>% 
  rename(n_unsolved = n)

n_homi_unsolved = full_join(nhomicide, nunsolved) # combine above information in one dataframe without omit
 
n_homi_unsolved %>% 
  knitr::kable()

```

**The table shows the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”) for each city.**

* For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r prop test}
unsolved = homicide %>% 
  unite(city, state, col = "city_state", sep = ", ") %>% 
  filter(city_state == "Baltimore, MD") %>% # specify city of Baltimore, MD
  count(disposition == "Open/No arrest") %>% # to specify unsolved homicides
  janitor::clean_names() %>% 
  rename(unsolved_homicide = disposition_open_no_arrest) %>% 
  pull(n) # pull certain vector for prop.test

result = prop.test(unsolved[1], sum(unsolved)) # save initial output of prop.test

pull1 = function(x){ # write a function to pull several variables
  broom::tidy(result) %>% 
    janitor::clean_names() %>%
    pull(x)
}

key = c("estimate", "conf_low", "conf_high") # referred to estimated proportion, low limit and upper limit of confidence interval
result1 = map(key, pull1)
```

**For Baltimore, MD, the estimated proportion is `r result1[1]` , the confidence interval is (`r result1[2]`, `r result1[3]`).**

* Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and  unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

```{r estimate and CI for cities}
ptest = function(x, y){ # write a function to run prop.test and extract certain information which can applied to each city
  prop.test(x, y) %>% 
    broom::tidy() %>% 
    janitor::clean_names() %>%
    select(estimate, conf_low, conf_high) %>% # referred to estimated proportion, low limit and upper limit of confidence interval
    unite(conf_low, conf_high, col = "CI", sep = " ~ ") # unite low limit and upper limit to obtain interval
}

homi_unsolved = homicide %>% 
  unite(city, state, col = "city_state", sep = ", ") %>% 
  group_by(city_state) %>% 
  count(disposition == "Open/No arrest") %>% 
  janitor::clean_names() %>% 
  spread(key = disposition_open_no_arrest, value = n) %>% 
  janitor::clean_names() %>% 
  mutate(sum = false + true) %>% # prepare data for argument of prop.test
  select(-false) %>% 
  filter(!is.na(true) & !is.na(sum)) %>% # omit NA for prop.test
  mutate(prop = map2(.x = true, .y = sum, ~ptest(.x, .y))) %>% # use purrr:map2 to apply function which requires 2 argument input for prop.test
  unnest() %>% # unnest to be tidy
  select(-true, -sum)

homi_unsolved %>% 
  knitr::kable()

```

* Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

```{r plot}
homi_unsolved %>% 
  separate(col = CI, into = c("lower", "upper"), sep = " ~ ") %>% # prepare data for geom_errorbar "aes"
  mutate(lower = as.numeric(lower), upper = as.numeric(upper)) %>% 
  ungroup() %>% 
  mutate(city_state = forcats::fct_reorder(city_state, estimate)) %>% # organize cities in ascending order of proportion of unsolved homicides
  ggplot() +
  geom_point(aes(x = city_state, y = estimate), color = "pink", size = 1.8) + # plot estimates for each city
  geom_errorbar(aes(x = city_state, ymin = lower, ymax = upper), width = 0.2, alpha = 0.5) + # add error bars based on upper and lower limits of CI for each city
  labs(
    title = "Estimates and CIs of proportions of unsolved homicides for each city",
    x = "City",
    y = "Estimate and CI"
  ) +
  theme(axis.text.x = element_text(size = 5, angle = 45, hjust = 1),
        axis.text.y = element_text(size = 4)) # make city_state names readable
```

